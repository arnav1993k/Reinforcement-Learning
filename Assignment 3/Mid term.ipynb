{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from agent import Agent_Linear,Agent_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "#For linear the best model was found when the position variables were removed. \n",
    "#The lander was landing itself but not at the correct spot\n",
    "arr = [2,3,4,5,6,7]\n",
    "nS = len(arr)\n",
    "nA = env.action_space.n\n",
    "\n",
    "#Declaring an agent\n",
    "agent1 = Agent_Linear(nS,nA,0,0,0.99)\n",
    "agent1.model.load_weights(\"./models/trained_agent_lin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the linear function are as follows\n",
      " [array([[ 0.64664346,  0.35784838, -0.07407869, -0.7654684 ],\n",
      "       [ 0.08706947, -0.6304708 , -0.38702783,  0.39825666],\n",
      "       [-0.25051776,  0.2206514 ,  0.56156796,  0.21887243],\n",
      "       [ 0.30966195, -0.64927506,  0.07129554, -0.08717282],\n",
      "       [-0.5983997 ,  0.50794524, -0.10142501,  0.63731307],\n",
      "       [ 0.4112801 ,  0.41075024,  0.640681  , -0.01457109]],\n",
      "      dtype=float32), array([-0.00025543, -0.00021271,  0.00010817, -0.00018867], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights of the linear function are as follows\\n\",agent1.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Video for linear approximator</h2>\n",
       "<br>\n",
       "<video width=\"600\" height=\"400\" controls>\n",
       "  <source src=\"./videos/linear.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h2> Video for linear approximator</h2>\n",
    "<br>\n",
    "<video width=\"600\" height=\"400\" controls>\n",
    "  <source src=\"./videos/linear.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Video for neural network</h2>\n",
       "<br>\n",
       "<div style=\"align-items:center\">\n",
       "<video width=\"600\" height=\"400\" controls>\n",
       "  <source src=\"./videos/neural.mp4\" type=\"video/mp4\">\n",
       "</video>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h2> Video for neural network</h2>\n",
    "<br>\n",
    "<div style=\"align-items:center\">\n",
    "<video width=\"600\" height=\"400\" controls>\n",
    "  <source src=\"./videos/neural.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convergence plots for Linear approximation</h3>\n",
    "<img src=\"./Plots/loss_lin.png\" alt=\"Linear Loss\" style=\"float: left; margin-right: 10px;\" />\n",
    "<img src=\"./Plots/rewards_lin.png\" alt=\"Linear Reward\" style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convergence plots for Neural network approximation</h3>\n",
    "<img src=\"./Plots/loss.png\" alt=\"Neural Loss\" style=\"float: left; margin-right: 10px;\" />\n",
    "<img src=\"./Plots/rewards.png\" alt=\"Neural Reward\" style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Linear function Approximation\n",
    "\\begin{equation}\n",
    "Q(s,.) = W^T\\theta\\\\\n",
    "W\\in R^{nS\\times{nA}}\\\\\n",
    "\\theta --> \\text{feature vector}\n",
    "\\end{equation}\n",
    "<p>Gradient</p>\n",
    "\\begin{equation}\n",
    "\\nabla Q(s,a) = \\theta\\\\\n",
    "\\theta \\in R^{nS\\times 1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) It was found that after removing the positional features from the input of the linear function approximator the rewards started coming up and the lander started getting smooth landings. Although the landings were outside of the marked area. This kind of feature selection was based on a hit and trial method. In addition since we are following stochastic gradient descent which depends a lot on the learning rate, therefore we need to be careful about setting it. Using decay and momentum helped to imrove convergence with otherwise was diverging.\n",
    "<p>\n",
    "The other possible ways of improving the performance can be by using feature engineering tricks likes projection to a different space using kernels. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Neural network with <br>\n",
    "<ul>\n",
    "    <li>2 hidden layers </li>\n",
    "    <li>64 units in each </li>\n",
    "    <li> ReLU non-linearity</li>\n",
    "    <li> Loss = mean squared error loss </li>\n",
    "    <li> ADAM optimizer(learning_rate = 0.0001)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) It was observed that the neural network performed better than the linear function approaximator. Although, for linear approximation convergence is almost guaranteed still it does not converge which can be due to two reasons:-<br>\n",
    "a. It is not able to learn non linearities.<br>\n",
    "b. It does not have significantly good parameters to learn from.<br>\n",
    "<p>\n",
    "For training the neural network a kind of experience replay along with target network was used which helped to provide for the required dataset for training the neural network on batches. It performs good because of its capability to learn non-linearities and also a greater set of training data available per gradient update.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
